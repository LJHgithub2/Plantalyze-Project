{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPMlv40pGK/dUrpDUFYwa2y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## [Yolov5] Custom Dataset으로 YOLO 학습\n","- 목표 : 잎 탐지 전용 Yolo모델\n","- 활용 데이터 셋 : hub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=153\n","- GCP를 활용하여 대규모 데이터셋을 학습\n","  - GCP Vertex AI\n","    - GCP에서 제공하는 통합 AI 서비스\n","    - Voertex AI - Colab Enterprise 사용\n","      - 런타임 템플릿\n","        - 별도의 인증없이 사용가능한 g2-standard-4 가속기 사용\n","        - GPU 유형 : NVIDIA_L4 * 1개\n","        - 스토리지 용량 : 2000GB\n","  - 데이터 요약\n","    - 모든 데이터는 총 45601개의 이미지 및 라벨링 데이터\n","      - 식물의 잎의 정보를 가지고있는 데이터는 총 28907개\n","    - 토마토, 고추, 상추 데이터 존재\n","    - 학습, 검증, 테스트 데이터 분류 기준\n","      - 학습 : 전체이미지의 95% (27461개)\n","      - 검증 : 전체이미지의 3% (867개)\n","      - 테스트 : 전체이미지의 2% (579개)\n","  - 에포크 : 40\n","  \n","\n"],"metadata":{"id":"KA-BGlEoLScC"}},{"cell_type":"markdown","source":["### 기존에 구축하였던 Yolo 커스텀 데이터셋 학습 폴더\n","\n","- Yolo train 폴더 구조\n","  - CustomDataset <br>\n","  ㄴ train/<br>\n","  &nbsp;&nbsp;&nbsp; 1.jpg(이미지 파일)<br>\n","  &nbsp;&nbsp;&nbsp; 1.txt(어노테이션 파일)<br>\n","  ㄴ valid/<br>\n","  &nbsp;&nbsp;&nbsp; 2.jpg(이미지 파일)<br>\n","  &nbsp;&nbsp;&nbsp; 2.txt(어노테이션 파일)<br>\n","  ㄴ test/<br>\n","  &nbsp;&nbsp;&nbsp; 3.jpg(이미지 파일)<br>\n","  &nbsp;&nbsp;&nbsp; 3.txt(어노테이션 파일)<br>\n","  config.yaml<br>"],"metadata":{"id":"JATtZ73MNVGc"}},{"cell_type":"markdown","source":["#### 폴더안의 모든 이미지 파일 및 어노테이션 파일 경로 읽기\n","- 이 함수는 지정된 루트 디렉토리에서 서브셋으로 지정된 하위 디렉토리들에 대해 지정된 확장자를 가진 파일들의 리스트를 가져옵니다. 이를 통해 커스텀 데이터셋의 이미지 파일 및 어노테이션 파일의 경로를 쉽게 얻을 수 있습니다.\n","- 매개변수\n","  - root_dir : 파일을 검색할 루트 디렉토리 경로입니다.\n","  - subsets : 검색할 하위 디렉토리 이름을 포함하는 리스트입니다. 주로 \"train\", \"valid\", \"test\"와 같이 학습, 검증, 테스트 등의 하위 데이터셋을 지정합니다.\n","  - extensions : 검색할 파일의 확장자를 포함하는 리스트입니다. 예를 들어, \"json\", \"txt\", \"jpg\", \"png\" 등이 될 수 있습니다."],"metadata":{"id":"nahIv_em63AQ"}},{"cell_type":"code","source":["import glob\n","import os\n","\n","def get_subsets_file_list(root_dir, subsets, extensions):\n","    file_lists = {subset: [] for subset in subsets}\n","\n","    for subset in subsets:\n","        for ext_label in extensions:\n","            file_lists[subset].extend(glob.glob(os.path.join(root_dir, subset, f\"*.{ext_label}\")))\n","\n","    return file_lists"],"metadata":{"id":"dXsrvlVR7Ln4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 파일 리스트를 텍스트 파일로 변환하기\n","- 이 함수는 파일 리스트를 텍스트 파일로 저장하는 기능을 합니다. 각 파일 리스트는 하나의 텍스트 파일에 한 줄씩 저장됩니다.\n","\n","- 매개변수\n","  - file_list: 저장할 파일 경로 리스트입니다.\n","  - output_path: 파일 리스트를 저장할 텍스트 파일의 경로입니다."],"metadata":{"id":"LqRF-f9a98Uy"}},{"cell_type":"code","source":["def write_file_list_to_txt(file_list, output_path):\n","    if os.path.exists(output_path):\n","        os.remove(output_path)\n","    with open(output_path, 'w') as f:\n","        f.write('\\n'.join(file_list) + '\\n')"],"metadata":{"id":"q1RubVBXay6L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 실행"],"metadata":{"id":"jTzsye4z_-0L"}},{"cell_type":"markdown","source":["#### 환경 변수 설정\n","- root_dir: 데이터셋이 위치한 루트 디렉토리의 경로입니다. 이 디렉토리 안에는 훈련, 검증, 테스트 데이터셋이 각각의 하위 디렉토리로 구성되어 있습니다.\n","- extensions: 데이터셋에서 사용되는 파일의 확장자를 지정한 리스트입니다. 여기서는 주로 이미지 파일과 어노테이션 파일을 나타내는 확장자들이 포함됩니다.\n","- subsets: 데이터셋을 훈련, 검증, 테스트 등의 서브셋으로 분할할 때 사용할 서브셋의 이름을 포함하는 리스트입니다.\n","- yaml_path: YAML 파일을 저장할 경로를 지정합니다. 이 파일은 설정된 데이터셋의 구성을 저장하게 됩니다.\n","- save_path: 모델을 학습하고 나서 생성된 가중치 파일을 저장할 경로"],"metadata":{"id":"5vhlbmfWAF8r"}},{"cell_type":"code","source":["root_dir = \"/content/YOLO_CustomDataSet_V2/\"\n","extensions = [\"json\", \"txt\", \"jpg\", \"JPG\", \"png\", \"PNG\"]\n","subsets = [\"train\", \"valid\", \"test\"]\n","yaml_path = os.path.join(root_dir, \"config.yaml\")\n","save_path = \"/content/models/leaf_detection.pt\""],"metadata":{"id":"xHazJ_C4ALtc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### (번외) YOLO 형식의 어노테이션 파일(.txt)의 일부 내용을 바꾸기\n","  - 폴더 구축과정에서 실수로 class code를 잘 못 설정하였을때 각 subsets 폴더에 직접 어노테이션 파일을 업데이트"],"metadata":{"id":"pfN0uzHeu-W6"}},{"cell_type":"code","source":["import os\n","\n","def map_plant_codes(folder_path, plant_code_mapping):\n","    # 폴더 내의 모든 .txt 파일을 찾습니다.\n","    for filename in os.listdir(folder_path):\n","        if filename.endswith(\".txt\"):\n","            file_path = os.path.join(folder_path, filename)\n","            lines = []\n","\n","            # 각 .txt 파일을 읽어서 매핑을 적용합니다.\n","            with open(file_path, \"r\") as file:\n","                for line in file:\n","                    class_index, *values = line.strip().split(\" \")\n","                    mapped_class_index = plant_code_mapping.get(class_index, class_index)\n","                    new_line = f\"{mapped_class_index} {' '.join(values)}\"\n","                    lines.append(new_line)\n","\n","            # 수정된 내용을 파일에 씁니다.\n","            with open(file_path, \"w\") as file:\n","                file.write(\"\\n\".join(lines))"],"metadata":{"id":"Le1qEw_BwjNf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 0: 고추, 1: 토마토, 11: 상추\n","for subfolder in subsets:\n","  folder_path = \"/content/YOLO_CustomDataSet_V2/\" + subfolder\n","  plant_code_mapping = {\"02\": \"0\", \"05\": \"1\", \"11\": \"2\"}\n","\n","  # 함수를 호출하여 매핑 작업을 수행합니다.\n","  map_plant_codes(folder_path, plant_code_mapping)"],"metadata":{"id":"G0W-txOkvg8t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 학습 폴더 구축"],"metadata":{"id":"AH7OAyMnAw8v"}},{"cell_type":"code","source":["# 하위폴더에 있는 파일의 경로를 읽는다.\n","file_lists = get_subsets_file_list(root_dir, subsets, extensions)\n","\n","# 각 서브셋 폴더에 해당하는 파일 경로를 저장한 텍스트 파일 생성\n","for subfolder in subsets:\n","  write_file_list_to_txt(file_lists[subfolder], os.path.join(root_dir, f\"{subfolder}.txt\"))"],"metadata":{"id":"6rBFsDu--sJj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### config.yaml 파일 생성\n","- YAML 형식으로 데이터를 저장하는 과정입니다.\n","\n","- data 딕셔너리에는 다음 내용이 포함되어 있습니다:\n","\n","  - \"train\": 훈련 데이터셋 파일 경로 (train.txt)\n","  - \"val\": 검증 데이터셋 파일 경로 (valid.txt)\n","  - \"test\": 테스트 데이터셋 파일 경로 (train.txt)\n","  - \"names\": 클래스 이름과 해당 인덱스를 매핑한 딕셔너리\n","- yaml.dump() 함수를 사용하여 이 데이터를 YAML 형식으로 파일에 저장합니다. 파일 경로는 yaml_path 변수에 지정되어 있습니다.\n","\n","- 검증\n","  - 저장된 YAML 파일을 확인하기 위해, yaml.safe_load() 함수를 사용하여 파일을 읽고 그 내용을 출력합니다."],"metadata":{"id":"1HH_T7l3-yim"}},{"cell_type":"code","source":["import yaml\n","class_names = {0: '고추', 1: '토마토', 2: '상추'}\n","data = {\n","    \"train\": os.path.join(root_dir, \"train.txt\"),\n","    \"val\": os.path.join(root_dir, \"valid.txt\"),\n","    \"test\": os.path.join(root_dir, \"train.txt\"),\n","    \"names\": class_names\n","}\n","with open(yaml_path, 'w') as f :\n","    yaml.dump(data, f)\n","\n","# 저장된 yaml파일 검증\n","with open(yaml_path, 'r') as f :\n","    lines = yaml.safe_load(f)\n","    print(lines)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lTqB7xehb318","executionInfo":{"status":"ok","timestamp":1714300133418,"user_tz":-540,"elapsed":851,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"}},"outputId":"653b758b-1818-4622-c31f-312720fde40a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'names': {0: 'leaf'}, 'test': '/content/drive/MyDrive/Colab Notebooks/Project/Chungbuk University/Capstone Design/AI_Model/PlantDiseaseDetection/data/YOLO_CustomDataSet/train.txt', 'train': '/content/drive/MyDrive/Colab Notebooks/Project/Chungbuk University/Capstone Design/AI_Model/PlantDiseaseDetection/data/YOLO_CustomDataSet/train.txt', 'val': '/content/drive/MyDrive/Colab Notebooks/Project/Chungbuk University/Capstone Design/AI_Model/PlantDiseaseDetection/data/YOLO_CustomDataSet/valid.txt'}\n"]}]},{"cell_type":"markdown","source":["#### YOLO 모델 불러오기\n","- ultralytics는 딥러닝 및 컴퓨터 비전 작업을 위한 파이썬 패키지입니다. 주로 객체 검출(Object Detection), 객체 추적(Object Tracking), 세그멘테이션(Segmentation) 등의 작업을 위한 유틸리티 및 모델을 제공합니다. 특히, YOLO(You Only Look Once) 객체 검출 알고리즘을 구현한 모델 및 관련 도구들을 제공하여 객체 검출 작업을 쉽게 수행할 수 있습니다."],"metadata":{"id":"ivrAdwRUC_82"}},{"cell_type":"code","source":["!pip install ultralytics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7f8UFWXapHAQ","executionInfo":{"status":"ok","timestamp":1714300200337,"user_tz":-540,"elapsed":66921,"user":{"displayName":"jonghyeon LEE","userId":"11309282343906360601"}},"outputId":"0a00256a-cb83-40fe-8585-13a7c101e0fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.2.4-py3-none-any.whl (752 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/752.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.4/752.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m752.1/752.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.1+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.17.1+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Collecting thop>=0.1.1 (from ultralytics)\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop, ultralytics\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 thop-0.1.1.post2209072238 ultralytics-8.2.4\n"]}]},{"cell_type":"code","source":["from ultralytics import YOLO\n","\n","# 미리 학습된 YOLOv8 모델 가중치와 구조를 불러옵니다.\n","model = YOLO('yolov8s.pt')\n","\n","# YAML 파일에 있는 정보를 사용하여 모델을 fine-tuning 합니다. 학습을 20 에포크 동안 진행합니다.\n","model.train(data=yaml_path, epochs=20)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G9nnkT0nc8-j","outputId":"a63fb4b2-b2c3-4ab6-aec5-1c05805e004d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt to 'yolov8s.pt'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 21.5M/21.5M [00:00<00:00, 202MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.2.4 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/drive/MyDrive/Colab Notebooks/Project/Chungbuk University/Capstone Design/AI_Model/PlantDiseaseDetection/data/YOLO_CustomDataSet/config.yaml, epochs=20, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 755k/755k [00:00<00:00, 24.9MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Overriding model.yaml nc=80 with nc=1\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n","Model summary: 225 layers, 11135987 parameters, 11135971 gradients, 28.6 GFLOPs\n","\n","Transferred 349/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 6.23M/6.23M [00:00<00:00, 107MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Colab Notebooks/Project/Chungbuk University/Capstone Design/AI_Model/PlantDiseaseDetection/data/YOLO_CustomDataSet/train.cache... 258 images, 15 backgrounds, 0 corrupt: 100%|██████████| 273/273 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/Colab Notebooks/Project/Chungbuk University/Capstone Design/AI_Model/PlantDiseaseDetection/data/YOLO_CustomDataSet/train/V006_77_0_00_10_03_12_0_c15_20201229_0014_S01_3.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/Colab Notebooks/Project/Chungbuk University/Capstone Design/AI_Model/PlantDiseaseDetection/data/YOLO_CustomDataSet/train/V006_77_0_00_10_03_12_0_c15_20201229_0015_S01_3.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/Colab Notebooks/Project/Chungbuk University/Capstone Design/AI_Model/PlantDiseaseDetection/data/YOLO_CustomDataSet/train/V006_77_0_00_10_03_12_0_c15_20201229_0017_S01_3.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/Colab Notebooks/Project/Chungbuk University/Capstone Design/AI_Model/PlantDiseaseDetection/data/YOLO_CustomDataSet/train/V006_77_0_00_10_03_12_0_c15_20201229_0018_S01_3.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/Colab Notebooks/Project/Chungbuk University/Capstone Design/AI_Model/PlantDiseaseDetection/data/YOLO_CustomDataSet/train/V006_77_0_00_10_03_12_0_c15_20201229_0019_S01_3.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/Colab Notebooks/Project/Chungbuk University/Capstone Design/AI_Model/PlantDiseaseDetection/data/YOLO_CustomDataSet/train/V006_77_0_00_10_03_12_0_c15_20201229_0020_S01_3.jpg: corrupt JPEG restored and saved\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Colab Notebooks/Project/Chungbuk University/Capstone Design/AI_Model/PlantDiseaseDetection/data/YOLO_CustomDataSet/valid.cache... 0 images, 9 backgrounds, 0 corrupt: 100%|██████████| 9/9 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["WARNING ⚠️ No labels found in /content/drive/MyDrive/Colab Notebooks/Project/Chungbuk University/Capstone Design/AI_Model/PlantDiseaseDetection/data/YOLO_CustomDataSet/valid.cache, training may not work correctly. See https://docs.ultralytics.com/datasets/detect for dataset formatting guidance.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to runs/detect/train/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/detect/train\u001b[0m\n","Starting training for 20 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       1/20      4.24G     0.8485      3.029      1.377          2        640: 100%|██████████| 18/18 [00:43<00:00,  2.41s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.42s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all          9          0          0          0          0          0\n","WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       2/20      4.16G     0.5999      1.121      1.105          4        640: 100%|██████████| 18/18 [00:26<00:00,  1.49s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.62it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          9          0          0          0          0          0\n","WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       3/20      4.18G      0.644     0.9333      1.128          4        640: 100%|██████████| 18/18 [00:27<00:00,  1.51s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  8.70it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          9          0          0          0          0          0\n","WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       4/20      4.18G      0.716     0.8646      1.193          2        640: 100%|██████████| 18/18 [00:26<00:00,  1.48s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  8.53it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          9          0          0          0          0          0\n","WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       5/20      4.18G     0.7549     0.8694        1.2          4        640: 100%|██████████| 18/18 [00:26<00:00,  1.49s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.30it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          9          0          0          0          0          0\n","WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       6/20      4.17G     0.6662     0.7812      1.131          2        640: 100%|██████████| 18/18 [00:27<00:00,  1.51s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.94it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          9          0          0          0          0          0\n","WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       7/20      4.18G     0.6777     0.7521      1.119          4        640: 100%|██████████| 18/18 [00:29<00:00,  1.64s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  8.80it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          9          0          0          0          0          0\n","WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       8/20      4.18G     0.7106     0.7824      1.163          2        640: 100%|██████████| 18/18 [00:25<00:00,  1.42s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  8.32it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          9          0          0          0          0          0\n","WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       9/20      4.17G     0.6051     0.6524      1.076          1        640: 100%|██████████| 18/18 [00:26<00:00,  1.45s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 10.34it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          9          0          0          0          0          0\n","WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      10/20      4.18G     0.6247     0.6679       1.13          2        640: 100%|██████████| 18/18 [00:24<00:00,  1.36s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 14.68it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          9          0          0          0          0          0\n","WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      11/20      4.17G     0.4827     0.7304      1.038          1        640: 100%|██████████| 18/18 [00:39<00:00,  2.22s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.86it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          9          0          0          0          0          0\n","WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      12/20      4.35G     0.4513     0.5325      0.997          1        640: 100%|██████████| 18/18 [00:27<00:00,  1.54s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.04it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          9          0          0          0          0          0\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      13/20      4.17G      0.396     0.8429     0.9041          0        640: 100%|██████████| 18/18 [00:29<00:00,  1.66s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 10.46it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          9          0          0          0          0          0\n","WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      14/20      4.19G     0.4075     0.4613     0.9393          1        640: 100%|██████████| 18/18 [00:28<00:00,  1.56s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 10.29it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          9          0          0          0          0          0\n","WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      15/20      4.17G     0.3643     0.4201     0.9219          1        640: 100%|██████████| 18/18 [00:24<00:00,  1.38s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.12it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          9          0          0          0          0          0\n","WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      16/20      4.19G     0.3479     0.3945      0.941          1        640: 100%|██████████| 18/18 [00:26<00:00,  1.48s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.23it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          9          0          0          0          0          0\n","WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      17/20      4.11G     0.3358     0.4018     0.8875         16        640:  33%|███▎      | 6/18 [00:08<00:16,  1.37s/it]"]}]},{"cell_type":"markdown","source":["#### 학습된 가중치 파일을 저장"],"metadata":{"id":"qFqc8BjDGtz4"}},{"cell_type":"code","source":["# 모델 객체 생성\n","model = YOLO('/content/runs/detect/train/weights/best.pt')\n","\n","# 학습된 가중치 파일을 특정 경로에 저장\n","model.save(save_path)"],"metadata":{"id":"OQtlsfeFGBUQ"},"execution_count":null,"outputs":[]}]}